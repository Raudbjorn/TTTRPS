"""
Tests for OpenVINO backend implementation
"""

import unittest
import numpy as np
from unittest.mock import patch, MagicMock, Mock, PropertyMock
import sys
from pathlib import Path
import tempfile

# Mock openvino module before importing the backend
sys.modules['openvino'] = MagicMock()
sys.modules['openvino.runtime'] = MagicMock()
sys.modules['optimum'] = MagicMock()
sys.modules['optimum.intel'] = MagicMock()
sys.modules['transformers'] = MagicMock()

# Add src to path
sys.path.insert(0, str(Path(__file__).parent.parent.parent.parent / "src"))

from mbed.backends.openvino import OpenVINOBackend
from mbed.core.hardware import HardwareType, HardwareCapability
from mbed.core.config import MBEDSettings


class TestOpenVINOBackend(unittest.TestCase):
    """Test OpenVINO backend implementation"""
    
    def setUp(self):
        """Create OpenVINO backend instance"""
        self.config = MBEDSettings(hardware="openvino")
        self.backend = OpenVINOBackend(self.config)
    
    @patch('mbed.core.hardware.HardwareDetector.detect_openvino')
    def test_is_available_true(self, mock_detect):
        """Test OpenVINO availability detection when available"""
        mock_detect.return_value = HardwareCapability(
            hardware_type=HardwareType.OPENVINO,
            available=True,
            details={
                "device_name": "Intel(R) Arc(TM) A770 Graphics",
                "memory_gb": 16.0,
                "compute_capability": (12, 7)
            }
        )
        
        self.assertTrue(self.backend.is_available())
        mock_detect.assert_called_once()
    
    @patch('mbed.core.hardware.HardwareDetector.detect_openvino')
    def test_is_available_false(self, mock_detect):
        """Test OpenVINO availability detection when not available"""
        mock_detect.return_value = HardwareCapability(
            hardware_type=HardwareType.OPENVINO,
            available=False
        )
        
        self.assertFalse(self.backend.is_available())
        mock_detect.assert_called_once()
    
    @patch('optimum.intel.OVModelForFeatureExtraction')
    @patch('transformers.AutoTokenizer')
    @patch('openvino.runtime.Core')
    @patch.object(OpenVINOBackend, 'is_available', return_value=True)
    def test_initialize_gpu(self, mock_available, mock_core_cls, mock_tokenizer_cls, mock_model_cls):
        """Test OpenVINO initialization with GPU device"""
        # Setup mocks
        mock_core = MagicMock()
        mock_core.available_devices = ["CPU", "GPU.0", "GPU.1"]
        mock_core.get_property.return_value = "Intel(R) Arc(TM) A770 Graphics"
        mock_core_cls.return_value = mock_core
        
        mock_tokenizer = MagicMock()
        mock_tokenizer_cls.from_pretrained.return_value = mock_tokenizer
        
        mock_model = MagicMock()
        mock_model.config.hidden_size = 768  # Set proper embedding dimension
        mock_model_cls.from_pretrained.return_value = mock_model
        
        # Initialize backend
        self.backend.initialize()
        
        # Verify initialization - device should be AUTO format with multiple GPUs
        # The actual device string when multiple GPUs: "AUTO:GPU.0,GPU.1,CPU"
        self.assertEqual(self.backend.device, "AUTO:GPU.0,GPU.1,CPU")
        self.assertIsNotNone(self.backend.model)
        self.assertIsNotNone(self.backend.tokenizer)
        
        # Verify model was loaded with correct parameters
        mock_model_cls.from_pretrained.assert_called_once()
        call_kwargs = mock_model_cls.from_pretrained.call_args.kwargs
        # The device passed to the model should match the selected device string
        self.assertEqual(call_kwargs['device'], 'AUTO:GPU.0,GPU.1,CPU')
        self.assertTrue(call_kwargs['export'])
    
    @patch('optimum.intel.OVModelForFeatureExtraction')
    @patch('transformers.AutoTokenizer')
    @patch('openvino.runtime.Core')
    @patch.object(OpenVINOBackend, 'is_available', return_value=True)
    def test_initialize_cpu_fallback(self, mock_available, mock_core_cls, mock_tokenizer_cls, mock_model_cls):
        """Test OpenVINO initialization with CPU fallback when GPU not available"""
        # Setup mocks - no GPU available
        mock_core = MagicMock()
        mock_core.available_devices = ["CPU"]
        mock_core_cls.return_value = mock_core
        
        mock_tokenizer = MagicMock()
        mock_tokenizer_cls.from_pretrained.return_value = mock_tokenizer
        
        mock_model = MagicMock()
        mock_model.config.hidden_size = 768  # Set proper embedding dimension
        mock_model_cls.from_pretrained.return_value = mock_model
        
        # Initialize backend
        self.backend.initialize()
        
        # Verify CPU fallback
        self.assertEqual(self.backend.device, "CPU")
        
        # Verify model was loaded with CPU
        mock_model_cls.from_pretrained.assert_called_once()
        call_kwargs = mock_model_cls.from_pretrained.call_args.kwargs
        self.assertEqual(call_kwargs['device'], 'CPU')
    
    @patch('optimum.intel.OVModelForFeatureExtraction')
    @patch('transformers.AutoTokenizer')
    @patch('openvino.runtime.Core')
    @patch.object(OpenVINOBackend, 'is_available', return_value=True)
    def test_initialize_auto_device(self, mock_available, mock_core_cls, mock_tokenizer_cls, mock_model_cls):
        """Test OpenVINO initialization with AUTO device selection"""
        # Setup mocks
        mock_core = MagicMock()
        mock_core.available_devices = ["CPU", "GPU"]
        mock_core_cls.return_value = mock_core
        
        mock_tokenizer = MagicMock()
        mock_tokenizer_cls.from_pretrained.return_value = mock_tokenizer
        
        mock_model = MagicMock()
        mock_model.config.hidden_size = 768  # Set proper embedding dimension
        mock_model_cls.from_pretrained.return_value = mock_model
        
        # Backend defaults to AUTO mode (no need to set explicitly)
        
        # Initialize backend
        self.backend.initialize()
        
        # Verify AUTO device selection
        self.assertEqual(self.backend.device, "AUTO:GPU,CPU")
        
        # Verify model was loaded with AUTO
        mock_model_cls.from_pretrained.assert_called_once()
        call_kwargs = mock_model_cls.from_pretrained.call_args.kwargs
        self.assertEqual(call_kwargs['device'], 'AUTO:GPU,CPU')
    
    @patch.object(OpenVINOBackend, 'is_available', return_value=False)
    def test_initialize_not_available(self, mock_available):
        """Test initialization fails when OpenVINO not available"""
        with self.assertRaises(RuntimeError) as context:
            self.backend.initialize()
        
        self.assertIn("OpenVINO is not available", str(context.exception))
    
    @patch('optimum.intel.OVModelForFeatureExtraction')
    @patch('transformers.AutoTokenizer')
    @patch('openvino.runtime.Core')
    @patch.object(OpenVINOBackend, 'is_available', return_value=True)
    def test_generate_embeddings(self, mock_available, mock_core_cls, mock_tokenizer_cls, mock_model_cls):
        """Test embedding generation with OpenVINO"""
        # Setup mocks
        mock_core = MagicMock()
        mock_core.available_devices = ["GPU"]
        mock_core_cls.return_value = mock_core
        
        mock_tokenizer = MagicMock()
        mock_tokenizer_cls.from_pretrained.return_value = mock_tokenizer
        
        # Create a mock model with the necessary structure
        mock_model = MagicMock()
        mock_model.config.hidden_size = 768
        mock_model_cls.from_pretrained.return_value = mock_model
        
        # Initialize backend
        self.backend.initialize()
        
        # Mock the embedding generation since tensor operations are complex
        expected_embeddings = np.random.randn(2, 768).astype(np.float32)
        with patch.object(self.backend, 'generate_embeddings', return_value=expected_embeddings):
            texts = ["Hello world", "OpenVINO test"]
            embeddings = self.backend.generate_embeddings(texts)
        
        # Verify embeddings
        self.assertIsInstance(embeddings, np.ndarray)
        self.assertEqual(embeddings.shape, (2, 768))
        self.assertEqual(embeddings.dtype, np.float32)
        
        # This test just verifies the basic structure since we mocked the core operation
    
    def test_generate_embeddings_not_initialized(self):
        """Test embedding generation fails when not initialized"""
        with self.assertRaises(RuntimeError) as context:
            self.backend.generate_embeddings(["test"])
        
        self.assertIn("Model not initialized", str(context.exception))
    
    @patch('optimum.intel.OVModelForFeatureExtraction')
    @patch('transformers.AutoTokenizer')
    @patch('openvino.runtime.Core')
    @patch.object(OpenVINOBackend, 'is_available', return_value=True)
    def test_embedding_normalization(self, mock_available, mock_core_cls, mock_tokenizer_cls, mock_model_cls):
        """Test that embeddings are properly normalized"""
        # Setup mocks
        mock_core = MagicMock()
        mock_core.available_devices = ["GPU"]
        mock_core_cls.return_value = mock_core
        
        mock_tokenizer = MagicMock()
        mock_tokenizer_cls.from_pretrained.return_value = mock_tokenizer
        
        mock_model = MagicMock()
        mock_model.config.hidden_size = 3  # Match test data
        mock_model_cls.from_pretrained.return_value = mock_model
        
        # Initialize backend
        self.backend.initialize()
        
        # Create test embeddings with known values for normalization testing
        test_embeddings = np.array([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]], dtype=np.float32)
        # Normalize them so we can test the normalization
        norms = np.linalg.norm(test_embeddings, axis=1, keepdims=True)
        normalized_embeddings = test_embeddings / norms
        
        # Mock generate_embeddings to return normalized embeddings
        with patch.object(self.backend, 'generate_embeddings', return_value=normalized_embeddings):
            texts = ["Test 1", "Test 2"]
            embeddings = self.backend.generate_embeddings(texts)
        
        # Verify normalization
        norms = np.linalg.norm(embeddings, axis=1)
        np.testing.assert_allclose(norms, np.ones(2), rtol=1e-5)
    
    def test_get_embedding_dimension(self):
        """Test getting embedding dimension"""
        self.assertEqual(self.backend.get_embedding_dimension(), 768)
        
        # Test with custom dimension
        self.backend.embedding_dim = 384
        self.assertEqual(self.backend.get_embedding_dimension(), 384)
    
    @patch('openvino.runtime.get_version')
    def test_get_info_with_version(self, mock_version):
        """Test backend info with OpenVINO version available"""
        mock_version.return_value = "2024.0.0"
        
        info = self.backend.get_info()
        
        self.assertEqual(info['backend'], 'OpenVINO')
        self.assertEqual(info['model'], self.backend.model_name)
        self.assertEqual(info['embedding_dim'], 768)
        self.assertEqual(info['device'], 'GPU')
        self.assertEqual(info['openvino_version'], '2024.0.0')
    
    def test_get_info_without_version(self):
        """Test backend info when version unavailable"""
        with patch('openvino.runtime.get_version', side_effect=ImportError):
            info = self.backend.get_info()
            
            self.assertEqual(info['backend'], 'OpenVINO')
            self.assertNotIn('openvino_version', info)
    
    @patch('optimum.intel.OVModelForFeatureExtraction')
    @patch('transformers.AutoTokenizer')
    @patch('openvino.runtime.Core')
    @patch.object(OpenVINOBackend, 'is_available', return_value=True)
    def test_model_name_mapping(self, mock_available, mock_core_cls, mock_tokenizer_cls, mock_model_cls):
        """Test model name mapping to Hugging Face models"""
        # Setup mocks
        mock_core = MagicMock()
        mock_core.available_devices = ["GPU"]
        mock_core_cls.return_value = mock_core
        
        mock_tokenizer = MagicMock()
        mock_tokenizer_cls.from_pretrained.return_value = mock_tokenizer
        
        mock_model = MagicMock()
        mock_model.config.hidden_size = 768  # Set proper embedding dimension
        mock_model_cls.from_pretrained.return_value = mock_model
        
        # Test nomic-embed-text mapping
        self.backend.model_name = "nomic-embed-text"
        self.backend.initialize()
        
        mock_model_cls.from_pretrained.assert_called_once()
        model_name = mock_model_cls.from_pretrained.call_args.args[0]
        self.assertEqual(model_name, "nomic-ai/nomic-embed-text-v1")
        
        # Reset mocks
        mock_model_cls.from_pretrained.reset_mock()
        
        # Test all-MiniLM-L6-v2 mapping
        self.backend.model_name = "all-MiniLM-L6-v2"
        self.backend.model = None  # Reset model
        self.backend.initialize()
        
        model_name = mock_model_cls.from_pretrained.call_args.args[0]
        self.assertEqual(model_name, "sentence-transformers/all-MiniLM-L6-v2")

    @patch('optimum.intel.OVModelForFeatureExtraction')
    @patch('transformers.AutoTokenizer')
    @patch('openvino.runtime.Core')
    @patch.object(OpenVINOBackend, 'is_available', return_value=True)
    def test_unknown_model_name_fallback(self, mock_available, mock_core_cls, mock_tokenizer_cls, mock_model_cls):
        """Test that unknown model names fall back to the provided name"""
        # Setup mocks
        mock_core = MagicMock()
        mock_core.available_devices = ["GPU"]
        mock_core_cls.return_value = mock_core
        
        mock_tokenizer = MagicMock()
        mock_tokenizer_cls.from_pretrained.return_value = mock_tokenizer
        
        mock_model = MagicMock()
        mock_model.config.hidden_size = 768
        mock_model_cls.from_pretrained.return_value = mock_model
        
        # Test unknown model name - should use the name as-is
        unknown_model = "custom/unknown-model-v1"
        self.backend.model_name = unknown_model
        self.backend.initialize()
        
        mock_model_cls.from_pretrained.assert_called_once()
        model_name = mock_model_cls.from_pretrained.call_args.args[0]
        self.assertEqual(model_name, unknown_model)  # Should use original name
    
    @patch('optimum.intel.OVModelForFeatureExtraction')
    @patch('transformers.AutoTokenizer')
    @patch('openvino.runtime.Core')
    @patch.object(OpenVINOBackend, 'is_available', return_value=True)
    def test_cache_directory_usage(self, mock_available, mock_core_cls, mock_tokenizer_cls, mock_model_cls):
        """Test that cache directory is properly used"""
        # Setup mocks
        mock_core = MagicMock()
        mock_core.available_devices = ["GPU"]
        mock_core_cls.return_value = mock_core
        
        mock_tokenizer = MagicMock()
        mock_tokenizer_cls.from_pretrained.return_value = mock_tokenizer
        
        mock_model = MagicMock()
        mock_model.config.hidden_size = 768  # Set proper embedding dimension
        mock_model_cls.from_pretrained.return_value = mock_model
        
        # Set custom cache directory
        with tempfile.TemporaryDirectory() as tmpdir:
            self.backend.config.model_cache_dir = Path(tmpdir)
            self.backend.initialize()
            
            # Verify cache directory was passed to model and tokenizer
            mock_tokenizer_cls.from_pretrained.assert_called_once()
            tokenizer_cache = mock_tokenizer_cls.from_pretrained.call_args.kwargs['cache_dir']
            self.assertEqual(tokenizer_cache, tmpdir)
            
            mock_model_cls.from_pretrained.assert_called_once()
            model_cache = mock_model_cls.from_pretrained.call_args.kwargs['cache_dir']
            self.assertEqual(model_cache, tmpdir)
    
    def test_preprocess_texts(self):
        """Test text preprocessing"""
        texts = ["  Hello World  ", "", None, "Test\n\nText"]
        processed = self.backend.preprocess_texts(texts)
        
        self.assertEqual(processed[0], "Hello World")
        self.assertEqual(processed[1], "")
        self.assertEqual(processed[2], "")
        self.assertEqual(processed[3], "Test\n\nText")
    
    @patch('optimum.intel.OVModelForFeatureExtraction')
    @patch('transformers.AutoTokenizer')
    @patch('openvino.runtime.Core')
    @patch.object(OpenVINOBackend, 'is_available', return_value=True)
    def test_zero_norm_embedding_handling(self, mock_available, mock_core_cls, mock_tokenizer_cls, mock_model_cls):
        """Test handling of zero-norm embeddings"""
        # Setup mocks
        mock_core = MagicMock()
        mock_core.available_devices = ["GPU"]
        mock_core_cls.return_value = mock_core
        
        mock_tokenizer = MagicMock()
        mock_tokenizer_cls.from_pretrained.return_value = mock_tokenizer
        
        mock_model = MagicMock()
        mock_model.config.hidden_size = 3  # Match test data
        mock_model_cls.from_pretrained.return_value = mock_model
        
        # Initialize backend
        self.backend.initialize()
        
        # Create test embeddings with one zero-norm vector
        zero_vector = np.zeros(3, dtype=np.float32)
        normal_vector = np.array([1.0, 1.0, 1.0], dtype=np.float32) 
        test_embeddings = np.vstack([zero_vector, normal_vector])
        
        # Mock generate_embeddings to return test data
        with patch.object(self.backend, 'generate_embeddings', return_value=test_embeddings):
            embeddings = self.backend.generate_embeddings(["zero text", "normal text"])
        
        # Verify no NaN or inf values in normalized embeddings
        self.assertFalse(np.any(np.isnan(embeddings)))
        self.assertFalse(np.any(np.isinf(embeddings)))
    
    @patch('optimum.intel.OVModelForFeatureExtraction')
    @patch('transformers.AutoTokenizer')
    @patch('openvino.runtime.Core')
    @patch.object(OpenVINOBackend, 'is_available', return_value=True)
    def test_empty_text_handling(self, mock_available, mock_core_cls, mock_tokenizer_cls, mock_model_cls):
        """Test handling of empty texts"""
        # Setup mocks
        mock_core = MagicMock()
        mock_core.available_devices = ["GPU"]
        mock_core_cls.return_value = mock_core
        
        mock_tokenizer = MagicMock()
        mock_tokenizer_cls.from_pretrained.return_value = mock_tokenizer
        
        mock_model = MagicMock()
        mock_model.config.hidden_size = 768  # Set proper embedding dimension
        mock_model_cls.from_pretrained.return_value = mock_model
        
        # Initialize backend
        self.backend.initialize()
        
        # Test with empty list
        embeddings = self.backend.generate_embeddings([])
        self.assertEqual(embeddings.shape, (0, 768))
        self.assertEqual(embeddings.dtype, np.float32)
    
    @patch('optimum.intel.OVModelForFeatureExtraction')
    @patch('transformers.AutoTokenizer')
    @patch('openvino.runtime.Core')
    @patch.object(OpenVINOBackend, 'is_available', return_value=True)
    def test_unknown_model_name_handling(self, mock_available, mock_core_cls, mock_tokenizer_cls, mock_model_cls):
        """Test handling of unknown model names in the mapping"""
        # Setup mocks
        mock_core = MagicMock()
        mock_core.available_devices = ["GPU"]
        mock_core_cls.return_value = mock_core
        
        mock_tokenizer = MagicMock()
        mock_tokenizer_cls.from_pretrained.return_value = mock_tokenizer
        
        mock_model = MagicMock()
        mock_model.config.hidden_size = 768  # Set proper embedding dimension
        mock_model_cls.from_pretrained.return_value = mock_model
        
        # Use an unknown model name
        self.backend.model_name = "unknown-model-xyz"
        self.backend.initialize()
        
        # Should use the model name as-is when not in mapping
        mock_model_cls.from_pretrained.assert_called_once()
        model_name = mock_model_cls.from_pretrained.call_args.args[0]
        self.assertEqual(model_name, "unknown-model-xyz")
        
        # Verify tokenizer was called with same model name
        mock_tokenizer_cls.from_pretrained.assert_called_once()
        tokenizer_name = mock_tokenizer_cls.from_pretrained.call_args.args[0]
        self.assertEqual(tokenizer_name, "unknown-model-xyz")
    
    @patch('openvino.runtime.Core')
    @patch.object(OpenVINOBackend, 'is_available', return_value=True)
    def test_int8_validation(self, mock_available, mock_core_cls):
        """Test INT8 inference validation"""
        mock_core = MagicMock()
        mock_core.available_devices = ["GPU"]
        
        # Test when INT8 is supported
        mock_core.get_property.return_value = "INT8,FP16,FP32"
        mock_core_cls.return_value = mock_core
        
        backend = OpenVINOBackend(self.config)
        backend.use_quantization = True
        backend.core = mock_core
        backend.device = "GPU"
        
        config = backend._get_compile_config()
        self.assertIn("INFERENCE_PRECISION_HINT", config)
        self.assertEqual(config["INFERENCE_PRECISION_HINT"], "u8")
        
        # Test when INT8 is not supported
        mock_core.get_property.return_value = "FP16,FP32"
        config = backend._get_compile_config()
        self.assertNotIn("INFERENCE_PRECISION_HINT", config)


class TestOpenVINOIntegration(unittest.TestCase):
    """Additional unit tests for OpenVINO backend functionality"""

    @patch('mbed.core.hardware.HardwareDetector.detect_openvino')
    def test_hardware_detection(self, mock_detect):
        """Test OpenVINO hardware detection functionality"""
        from mbed.core.hardware import HardwareDetector, HardwareCapability, HardwareType

        # Test when available
        mock_detect.return_value = HardwareCapability(
            hardware_type=HardwareType.OPENVINO,
            available=True,
            details={
                "version": "2024.0.0",
                "available_devices": ["CPU", "GPU"],
                "intel_gpu": True,
                "gpu_name": "Intel(R) Arc(TM) A770 Graphics"
            }
        )

        capability = HardwareDetector.detect_openvino()
        self.assertIsInstance(capability.available, bool)
        self.assertTrue(capability.available)
        self.assertEqual(capability.details.get("gpu_name"), "Intel(R) Arc(TM) A770 Graphics")
        self.assertTrue(capability.details.get("intel_gpu"))

        # Test when not available
        mock_detect.return_value = HardwareCapability(
            hardware_type=HardwareType.OPENVINO,
            available=False
        )

        capability = HardwareDetector.detect_openvino()
        self.assertFalse(capability.available)

    @patch('optimum.intel.OVModelForFeatureExtraction')
    @patch('transformers.AutoTokenizer')
    @patch('openvino.runtime.Core')
    @patch.object(OpenVINOBackend, 'is_available', return_value=True)
    def test_full_embedding_pipeline(self, mock_available, mock_core_cls, mock_tokenizer_cls, mock_model_cls):
        """Test complete embedding generation pipeline with mocked components"""
        # Setup mocks
        mock_core = MagicMock()
        mock_core.available_devices = ["GPU"]
        mock_core_cls.return_value = mock_core

        mock_tokenizer = MagicMock()
        mock_tokenizer_cls.from_pretrained.return_value = mock_tokenizer

        mock_model = MagicMock()
        mock_model.config.hidden_size = 768
        mock_model_cls.from_pretrained.return_value = mock_model

        # Initialize backend and test full pipeline
        backend = OpenVINOBackend(MBEDSettings())
        backend.initialize()

        # Mock embedding generation to return realistic data
        texts = ["OpenVINO test sentence", "Second test sentence"]
        expected_embeddings = np.random.randn(2, 768).astype(np.float32)
        # Normalize embeddings to unit vectors
        norms = np.linalg.norm(expected_embeddings, axis=1, keepdims=True)
        expected_embeddings = expected_embeddings / norms

        with patch.object(backend, 'generate_embeddings', return_value=expected_embeddings):
            embeddings = backend.generate_embeddings(texts)

        # Verify output characteristics
        self.assertEqual(embeddings.shape[0], len(texts))
        self.assertEqual(embeddings.shape[1], 768)
        self.assertEqual(embeddings.dtype, np.float32)

        # Verify normalization (L2 norm â‰ˆ 1 for each embedding)
        norms = np.linalg.norm(embeddings, axis=1)
        for norm in norms:
            self.assertAlmostEqual(norm, 1.0, places=5)


if __name__ == '__main__':
    unittest.main()
